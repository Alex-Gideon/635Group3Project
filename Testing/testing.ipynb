{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.corpus\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_doc(doc, stoplist):\n",
    " # split into tokens by white space\n",
    " tokens = doc.split()\n",
    " # remove punctuation from each token\n",
    " table = str.maketrans('', '', punctuation)\n",
    " tokens = [w.translate(table) for w in tokens]\n",
    " # filter out tokens not in vocab\n",
    " tokens = [w for w in tokens if w.lower() not in stoplist]\n",
    " tokens = [w for w in tokens if not w.isdigit()]\n",
    " #tokens = ' '.join(tokens)\n",
    " return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bromwell', 'High', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'Teachers', 'years', 'teaching', 'profession', 'lead', 'believe', 'Bromwell', 'Highs', 'satire', 'much', 'closer', 'reality', 'Teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'see', 'right', 'pathetic', 'teachers', 'pomp', 'pettiness', 'whole', 'situation', 'remind', 'schools', 'knew', 'students', 'saw', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', '', '', 'High', 'classic', 'line', 'INSPECTOR', 'Im', 'sack', 'one', 'teachers', 'STUDENT', 'Welcome', 'Bromwell', 'High', 'expect', 'many', 'adults', 'age', 'think', 'Bromwell', 'High', 'far', 'fetched', 'pity', 'isnt']\n"
     ]
    }
   ],
   "source": [
    "with open('testing.txt','r') as file:\n",
    "    for line in file:\n",
    "        tokens = clean_doc(line,stop_words)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9,Bromwell,High,cartoon,comedy,ran,time,programs,school,life,\"\"\"Teachers\"\"\",My,years,teaching,profession,lead,believe,Bromwell,High's,satire,much,closer,reality,\"\"\"Teachers\"\"\",scramble,survive,financially,insightful,students,see,right,pathetic,teachers',pomp,pettiness,whole,situation,remind,schools,knew,students,When,saw,episode,student,repeatedly,tried,burn,school,immediately,recalled,nan,nan,High,A,classic,line:,INSPECTOR:,I'm,sack,teachers,STUDENT:,Welcome,Bromwell,High,expect,many,adults,age,think,Bromwell,High,far,fetched,pity,isn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with', 'his', 'itself', 'below', 'so', 'your', 'most', 'as', 'it', 'of', 'only', 'until', 'into', 'if', \"haven't\", 'shan', 'do', 'them', 'm', 'o', \"wouldn't\", 'doesn', 'yourself', 'whom', 'herself', 'and', \"needn't\", 'don', 'too', 'on', 'over', 'during', 'than', 'aren', 'same', 'me', 'y', 'some', \"you're\", \"should've\", \"weren't\", 'have', 'any', 'himself', 'but', 'at', 're', \"you'd\", 'd', 'each', 'doing', 'yours', 'the', 'down', 'are', 'once', \"isn't\", \"doesn't\", \"aren't\", 'again', 'a', 'couldn', 'myself', 'he', 'does', 'to', 'how', 'because', 'these', \"hadn't\", 'between', 'is', 'for', 'they', 'didn', 'here', 'no', 'mustn', 'why', 'theirs', \"shan't\", \"shouldn't\", \"don't\", 'this', \"you'll\", 'an', 'our', \"it's\", \"didn't\", 'there', 'isn', 'been', 'him', 'her', 'will', 'wouldn', \"wasn't\", 'few', 'its', 'what', 'while', 'very', 'hadn', 'hasn', 'up', 'had', 'through', \"won't\", 'off', 'll', 'were', 'or', 'above', 'who', 'before', 'out', 't', 'that', 'she', 'has', 'won', 'am', 'about', 'be', \"hasn't\", 'being', 'which', 'in', 'own', 'ain', 'was', 'from', 'nor', 'other', \"mightn't\", 'ours', 'needn', \"she's\", 'haven', 'just', 'you', 'yourselves', \"mustn't\", 'we', 'after', \"you've\", 'those', 'now', 's', 'mightn', 'by', 'such', 'weren', 'did', 'i', 'further', 'ma', 'under', 'can', 'all', \"couldn't\", 'shouldn', 'hers', 'then', 'against', 'when', 'more', 'where', 'should', 'themselves', \"that'll\", 'their', 'not', 'my', 'both', 've', 'ourselves', 'wasn', 'having'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "635Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
