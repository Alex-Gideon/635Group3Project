{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/stu4/s12/asg9582/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet \n",
    "from os import walk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "import csv\n",
    "from string import punctuation\n",
    "import re\n",
    "from bs4 import BeautifulSoup as beauty\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import chain\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment counts in tweets1:\n",
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Unique sentiment counts in tweets2:\n",
      " 1.0    72250\n",
      " 0.0    55213\n",
      "-1.0    35510\n",
      "Name: category, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised “minimum government maximum...      -1.0\n",
       "1       talk all the nonsense and continue all the dra...       0.0\n",
       "2       what did just say vote for modi  welcome bjp t...       1.0\n",
       "3       asking his supporters prefix chowkidar their n...       1.0\n",
       "4       answer who among these the most powerful world...       1.0\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "162977  did you cover her interaction forum where she ...       0.0\n",
       "162978  there big project came into india modi dream p...       0.0\n",
       "162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets1 = pd.read_csv('datasets/tweets-1.csv')\n",
    "tweets2 = pd.read_csv('datasets/tweets-2.csv')\n",
    "\n",
    "unique_sentiments_tweets1 = tweets1['sentiment'].value_counts()\n",
    "unique_sentiments_tweets2 = tweets2['category'].value_counts()\n",
    "print(\"Unique sentiment counts in tweets1:\")\n",
    "print(unique_sentiments_tweets1)\n",
    "print(\"\\nUnique sentiment counts in tweets2:\")\n",
    "print(unique_sentiments_tweets2)\n",
    "display(tweets1)\n",
    "display(tweets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets to AT-LSTM Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    80831\n",
      "negative    43290\n",
      "Name: sentiment, dtype: int64\n",
      "text         0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107762</th>\n",
       "      <td>engine growth modi unveils indias first 12000 ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107763</th>\n",
       "      <td>modi promised 2014 lok sabha elections that be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107764</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107765</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107766</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text sentiment\n",
       "0           Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "1                               my boss is bullying me...  negative\n",
       "2                          what interview! leave me alone  negative\n",
       "3        Sons of ****, why couldn`t they put them on t...  negative\n",
       "4       2am feedings for the baby are fun when he is a...  positive\n",
       "...                                                   ...       ...\n",
       "107762  engine growth modi unveils indias first 12000 ...  positive\n",
       "107763  modi promised 2014 lok sabha elections that be...  positive\n",
       "107764  why these 456 crores paid neerav modi not reco...  negative\n",
       "107765  dear rss terrorist payal gawar what about modi...  negative\n",
       "107766  have you ever listen about like gurukul where ...  positive\n",
       "\n",
       "[124121 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets1_atlstm = tweets1[tweets1['sentiment'] != 'neutral'][['text', 'sentiment']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "tweets2_atlstm = tweets2[tweets2['category'] != 0][['clean_text', 'category']].copy()\n",
    "tweets2_atlstm['sentiment'] = tweets2_atlstm['category'].map({-1.0: 'negative', 0.0: 'neutral', 1.0: 'positive'})\n",
    "tweets2_atlstm = tweets2_atlstm[['clean_text', 'sentiment']].reset_index(drop=True)\n",
    "tweets2_atlstm.rename(columns={'clean_text': 'text'}, inplace=True)\n",
    "\n",
    "unique_sentiments_tweets1 = tweets1_atlstm['sentiment'].value_counts()\n",
    "unique_sentiments_tweets2 = tweets2_atlstm['sentiment'].value_counts()\n",
    "tweets1_atlstm.dropna(inplace=True)\n",
    "tweets2_atlstm.dropna(inplace=True)\n",
    "combined_df = pd.concat([tweets1_atlstm, tweets2_atlstm])\n",
    "print(combined_df['sentiment'].value_counts())\n",
    "missing_values_count = combined_df.isnull().sum()\n",
    "print(missing_values_count)\n",
    "combined_df.rename(columns={'text': 'review'}).to_csv('datasets/atlstm_tweets.csv', index=False)\\\n",
    "\n",
    "display(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets to Bi_LSTM and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_html_tags(row):\n",
    "    return beauty(row, 'html.parser').text\n",
    "\n",
    "\n",
    "def tokenize(input_text):\n",
    "    tokens = re.sub('[^a-zA-Z]', ' ', input_text).lower().split()\n",
    "\n",
    "    # tokens = word_tokenizer.tokenize(input_text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def remove_stop_words(input_text_vector):\n",
    "    filtered = []\n",
    "    for word in input_text_vector:\n",
    "        if word.isalpha() and word not in stop_words:\n",
    "            filtered.append(word)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def standardize(input_label):\n",
    "    return 1 if input_label == 'positive' else 0\n",
    "\n",
    "\n",
    "def all_at_once(input_text):\n",
    "    cleaned = remove_html_tags(input_text)\n",
    "    cleaned = tokenize(cleaned)\n",
    "    cleaned = remove_stop_words(cleaned)\n",
    "    return cleaned\n",
    "\n",
    "def hypernym_list(tokens):\n",
    "    hypernym_tokens = []\n",
    "    for word in tokens:\n",
    "        My_sysn = wordnet.synsets(word)\n",
    "        if len(My_sysn) == 0:\n",
    "            hypernym_tokens.append(word)\n",
    "        else:\n",
    "            hypernym_tokens.append(My_sysn[0].lemma_names()[0])\n",
    "    return hypernym_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu4/s12/asg9582/miniconda3/envs/635Proj/lib/python3.7/site-packages/ipykernel_launcher.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized\n",
      "hypernymed 1...\n",
      "hypernymed 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>hypernym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[sooo, sad, girl, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>[foreman, bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "      <td>[son, put_option, release, already, buy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[eating, baby, fun, smile, coo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16358</th>\n",
       "      <td>enjoy ur night</td>\n",
       "      <td>positive</td>\n",
       "      <td>[enjoy, ur, night]</td>\n",
       "      <td>[enjoy, Ur, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16359</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, l...</td>\n",
       "      <td>[wish, could, semen, see, uracil, Denver, husb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16360</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wondered, rake, client, made, clear, net, for...</td>\n",
       "      <td>[wonder, rake, client, make, clear, internet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hect...</td>\n",
       "      <td>[Yay, good, enjoy, interruption, probably, nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16362</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[worth]</td>\n",
       "      <td>[worth]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  \\\n",
       "0          Sooo SAD I will miss you here in San Diego!!!  negative   \n",
       "1                              my boss is bullying me...  negative   \n",
       "2                         what interview! leave me alone  negative   \n",
       "3       Sons of ****, why couldn`t they put them on t...  negative   \n",
       "4      2am feedings for the baby are fun when he is a...  positive   \n",
       "...                                                  ...       ...   \n",
       "16358                                     enjoy ur night  positive   \n",
       "16359   wish we could come see u on Denver  husband l...  negative   \n",
       "16360   I`ve wondered about rake to.  The client has ...  negative   \n",
       "16361   Yay good for both of you. Enjoy the break - y...  positive   \n",
       "16362                         But it was worth it  ****.  positive   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0                          [sooo, sad, miss, san, diego]   \n",
       "1                                       [boss, bullying]   \n",
       "2                              [interview, leave, alone]   \n",
       "3                 [sons, put, releases, already, bought]   \n",
       "4                    [feedings, baby, fun, smiles, coos]   \n",
       "...                                                  ...   \n",
       "16358                                 [enjoy, ur, night]   \n",
       "16359  [wish, could, come, see, u, denver, husband, l...   \n",
       "16360  [wondered, rake, client, made, clear, net, for...   \n",
       "16361  [yay, good, enjoy, break, probably, need, hect...   \n",
       "16362                                            [worth]   \n",
       "\n",
       "                                                hypernym  \n",
       "0                          [sooo, sad, girl, san, diego]  \n",
       "1                                    [foreman, bullying]  \n",
       "2                              [interview, leave, alone]  \n",
       "3               [son, put_option, release, already, buy]  \n",
       "4                        [eating, baby, fun, smile, coo]  \n",
       "...                                                  ...  \n",
       "16358                                 [enjoy, Ur, night]  \n",
       "16359  [wish, could, semen, see, uracil, Denver, husb...  \n",
       "16360  [wonder, rake, client, make, clear, internet, ...  \n",
       "16361  [Yay, good, enjoy, interruption, probably, nee...  \n",
       "16362                                            [worth]  \n",
       "\n",
       "[16363 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets1_atlstm['tokenized'] = tweets1_atlstm['text'].apply(lambda x: all_at_once(x))\n",
    "tweets2_atlstm['tokenized'] = tweets2_atlstm['text'].apply(lambda x: all_at_once(x))\n",
    "print(\"tokenized\")\n",
    "tweets1_atlstm['hypernym'] = tweets1_atlstm['tokenized'].apply(lambda x: hypernym_list(x))\n",
    "print(\"hypernymed 1...\")\n",
    "tweets2_atlstm['hypernym'] = tweets2_atlstm['tokenized'].apply(lambda x: hypernym_list(x))\n",
    "print(\"hypernymed 2\")\n",
    "display(tweets1_atlstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, tokenized_csv_file, hypernyms_csv_file):\n",
    "    # Convert sentiment from letter to number\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'negative' else 10)\n",
    "    \n",
    "    # Write sentiment and tokenized columns to CSV\n",
    "    with open(tokenized_csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "        for index, row in df.iterrows():\n",
    "            sentiment = str(row['sentiment'])\n",
    "            tokenized = ','.join(row['tokenized'])\n",
    "            writer.writerow([sentiment, tokenized])\n",
    "    \n",
    "    # Write hypernyms column to CSV\n",
    "    with open(hypernyms_csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "        for index, row in df.iterrows():\n",
    "            hypernyms = ','.join(row['hypernym'])\n",
    "            if not hypernyms:\n",
    "                print(f\"Empty hypernyms list encountered at index {index}\")\n",
    "                print(row)\n",
    "            writer.writerow([hypernyms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text         0\n",
      "sentiment    0\n",
      "tokenized    0\n",
      "hypernym     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nullcount1 = tweets1_atlstm.isnull().sum()\n",
    "print(nullcount1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1_atlstm = tweets1_atlstm[(tweets1_atlstm['tokenized'].apply(len) > 0) & (tweets1_atlstm['hypernym'].apply(len) > 0)]\n",
    "tweets2_atlstm = tweets2_atlstm[(tweets2_atlstm['tokenized'].apply(len) > 0) & (tweets2_atlstm['hypernym'].apply(len) > 0)]\n",
    "\n",
    "process_dataframe(tweets1_atlstm,  \"datasets/small_tweets_bilstm.csv\", \"datasets/small_tweets_ANN.csv\")\n",
    "process_dataframe(tweets2_atlstm, \"datasets/big_tweets_bilstm.csv\", \"datasets/big_tweets_ANN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "635Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
